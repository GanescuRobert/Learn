{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "a51c484ec4fef5f002c8f467736c617cd38a373e870ae09731876c8e0d970dd0"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My laptop\n",
    "# RAM Memory  15.9 GB ; Speed 2667 MHz\n",
    "# GPU 6.0 GB ; GTX 1060 \n",
    "# CPU Base speed 2.20 GHz ; 6 cores ; 12 logical processors i7-8750h\n",
    "\n",
    "# Program use GPU&RAM at full potential ~95% in use. \n",
    "# It takes at least 6 hours with this specs.\n",
    "# I skipped running this program, but I replayed the video 4 times for a better understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example image from the dataset\n",
    "\n",
    "Image(url='hasyv2/hasy-data/v2-00010.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from PIL import Image as pil_image\n",
    "import keras.preprocessing.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images (as numpy arrays) and save their classes\n",
    "\n",
    "imgs = []\n",
    "classes = []\n",
    "\n",
    "with open('hasyv2/hasy-data-labels.csv') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    i = 0\n",
    "    for row in csvreader:\n",
    "        if i > 0:\n",
    "            img = keras.preprocessing.image.img_to_array(pil_image.open('hasyv2/'+row[0]))\n",
    "            # neuron activation functions behave best when input values are between 0.0 and 1.0 (or -1.0 and 1.0)\n",
    "            # so we rescale each pixel value to be in the range 0.0 to 1.0 instead of 0-255\n",
    "            img /=255.0\n",
    "            imgs.append((row[0],row[2],img))\n",
    "            classes.append(row[2])\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data, split into 80% train, 20% test\n",
    "\n",
    "import random\n",
    "random.shuffle(imgs)\n",
    "split_idx = int(0.8*len(imgs))\n",
    "train = imgs [:split_idx]\n",
    "test = imgs [split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_input = np.asarray(list(map(lambda row:row[2],train)))\n",
    "test_input = np.asarray(list(map(lambda row:row[2],test)))\n",
    "\n",
    "train_output = np.asarray(list(map(lambda row:row[1],train)))\n",
    "test_output = np.asarray(list(map(lambda row:row[1],test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class names into one-hot encoding\n",
    "\n",
    "# first, convert class names into integers\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(classes)\n",
    "\n",
    "# then convert integers into one-hot encoding\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded),1)\n",
    "onehot_encoder.fit(integer_encoded)\n",
    "\n",
    "#convert train and test output to one-hot\n",
    "train_output_int = label_encoder.transform(train_output)\n",
    "train_output = onehot_encoder.transform(train_output_int.reshape(len(train_output_int),1))\n",
    "\n",
    "test_output_int = label_encoder.transform(test_output)\n",
    "test_output = onehot_encoder.transform(test_output_int.reshape(len(test_output_int),1))\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print('Number of classed: %d'% num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(   32, \n",
    "                    kernel_size=(3,3), \n",
    "                    activation='relu', \n",
    "                    input_shape=np.shape(train_input[0])))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.callbacks\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='/logs/mnist-style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_input,train_output,\n",
    "            batch_size=32,\n",
    "            epochs=10,\n",
    "            verbose=2,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_input,test_output,verbose=2)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try various model configurations and parameters to find the best\n",
    "\n",
    "import time\n",
    "\n",
    "results= []\n",
    "for conv2d_count in [1,2]:\n",
    "    for dense_size in [128,256,512,1024,2048]:\n",
    "        for dropout in [0.0,0.25,0.50,0.75]:\n",
    "            model = Sequential()\n",
    "            for i in range(conv2d_count):\n",
    "                if i==0:\n",
    "                    model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=np.shape(train_input[0])))\n",
    "                else:\n",
    "                     model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(dense_size,activation='tanh'))\n",
    "            if dropout > 0.0:\n",
    "                model.add(Dropout(dropout))\n",
    "            model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            log_dir = '/logs/conv2d_%d-dense_%d-dropout_%.2f' % (conv2d_count,dense_size,dropout)\n",
    "            tensorboard = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "            start = time.time()\n",
    "            model.fit(train_input,train_output,batch_size=32,epochs=10,\n",
    "                        verbose=0,validation_split=0.2,callbacks=[tensorboard])\n",
    "            score = model.evaluate(test_input,test_output,verbose=2)\n",
    "            end = time.time()\n",
    "            elapsed = end-start\n",
    "            result = (conv2d_count,dense_size,dropout,score[0],score[1],elapsed)\n",
    "            print('Conv2D count: %d, Dense size: %d, Dropout: %.2f - Loss: %.2f, Accuracy: %.2f, Time %d sec' % result)\n",
    "        \n",
    "            results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 369)               47601     \n",
      "=================================================================\n",
      "Total params: 205,329\n",
      "Trainable params: 205,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "# rebuild / retrain a model with the best parameters (from the search) and use all data\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(   32, \n",
    "                    kernel_size=(3,3), \n",
    "                    activation='relu', \n",
    "                    input_shape=np.shape(train_input[0])))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# join train and test data so we train the network on all data we have available to us\n",
    "\n",
    "model.fit(np.concatenate((train_input,test_input)),\n",
    "            np.concatenate((train_output,test_output)),\n",
    "            batch_size=32,epochs=10,verbose=2)\n",
    "\n",
    "# save the trained model\n",
    "model.save('mathsymbols.model')\n",
    "\n",
    "# save label encoder (to reverse one-hot encoding)\n",
    "\n",
    "np.save('classes.npy', label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained model and predict the math symbol for an arbitrary imagel\n",
    "# the code below could be placed in a separate file\n",
    "\n",
    "import keras.models\n",
    "\n",
    "model2 = keras.models.load_model('mathsymbols.model')\n",
    "print(model2.summary())\n",
    "\n",
    "# restore the class name to integer encoder\n",
    "\n",
    "label_encoder2 = LabelEncoder()\n",
    "label_encoder2.classes_ = np.load('classes.npy')\n",
    "\n",
    "def predict(img_path):\n",
    "    newimg = keras.preprocessing.image.img_to_array(pil_image.open(img_path))\n",
    "    newimg /= 255.0\n",
    "\n",
    "    # do the prediction\n",
    "    prediction = model2.predict(newimg.reshape(1,32,32,3))\n",
    "\n",
    "    # figure out which output neuron had the highest score, and reverse the one-hot encoding\n",
    "    inverted = label_encoder2.inverse_transform([np.argmax(prediction)]) # argmax finds highest-scoring output\n",
    "    print(\"Prediction: %s, confidence: %.2f\" % (inverted[0], np.max(prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab an image ( we'll just use a random training image for demonstration purposes)\n",
    "predict('hasy-data/v2-00010.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}